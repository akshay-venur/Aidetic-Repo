# Aidetic-Repo

* There is a csv file which contains the earthquake data. This file is stored in the local machine.
* Crrate a database and table in local MySQL which will be used to store the earthquake data.
* Run a pyhton script which will load the csv file data into the MySQL database.
* Create a Azure MySQL server instance.
* In the local MySQL server using the migration wizard, move the data from local Mysql to Azure MySQL
* Create a Azure databricks Notebook and craete a cluster.
* Load the data from Azure MySQL database into Azure databricks using JDBC driver and store the data in pyspark dataframe.
* Answer the bussiness questions using PySpark.

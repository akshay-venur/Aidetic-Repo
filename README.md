# Aidetic-Repo

* There is a CSV file that contains the earthquake data. This file is stored in the local machine.
* Create a database and table in local MySQL which will be used to store the earthquake data.
* Run a Python script that will load the CSV file data into the MySQL database.
* Create an Azure MySQL server instance.
* In the local MySQL server using the migration wizard, move the data from local Mysql to Azure MySQL
* Create an Azure Databricks Notebook and create a cluster.
* Load the data from the Azure MySQL database into Azure data bricks using the JDBC driver and store the data in the pyspark data frame.
* Answer the business questions using PySpark.
